AWSTemplateFormatVersion: '2010-09-09'
Description: Template to create a Lambda function using a Python script and a dependencies ZIP file from an S3 bucket.

Parameters:
  EnvironmentType:
    Type: String
    Description: Dev, production, staging, etc
    Default: dev

  ExternalDepsBucket:
    Type: String
    Description: Name of the pre-existing S3 bucket containing the Python script and dependencies ZIP file.
    Default: 991175998352-cumulus-resources

  DependenciesZipKey:
    Type: String
    Description: S3 object key for the dependencies ZIP file.
    Default: patient_mapping_deps.zip

Resources:
  PatientBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::AccountId}-cumulus-gic-connector-${EnvironmentType}'
      AccessControl: Private
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true

  URILambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: S3PresignedURLPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                Resource: !Sub 'arn:aws:s3:::${PatientBucket}/*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'

  PresignedURLFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: GeneratePresignedURL
      Handler: index.handler
      Runtime: python3.12
      Role: !GetAtt URILambdaExecutionRole.Arn
      Code:
        ZipFile: |
          import json
          import uuid
          import logging
          import os

          import boto3
          from botocore.exceptions import NoCredentialsError

          site_name = 'bch'
          valid_file_names = ['patients.txt', site_name + '_genotypic_data.tsv']
          logger = logging.getLogger()
          logger.setLevel('INFO')

          def handler(event, context):
            permitted_bucket = os.environ['BUCKET_NAME']
            logging.info('Found permitted bucket name: %s', permitted_bucket)
            bucket_name = event.get('bucket_name')
            object_key = event.get('object_key')

            if not bucket_name or not object_key:
                return {
                    'statusCode': 400,
                    'body': json.dumps({'error': 'bucket_name and object_key are required'})
                }
            
            if bucket_name != permitted_bucket:
                return {
                    'statusCode': 400,
                    'body': json.dumps({'error': 'we cant upload to that bucket either'})
                }

            if not _validate_bucket_key(object_key):
                return {
                    'statusCode': 400,
                    'body': json.dumps({'error': 'object key must be a UUID directory followed by one of these files: {}'.format(valid_file_names)})
                }
            logging.info('Request to upload %s to %s is ok. Generating URL', object_key, bucket_name)
            
            s3_client = boto3.client('s3')
            try:
                presigned_url = s3_client.generate_presigned_url(
                    ClientMethod='put_object',
                    Params={
                        'Bucket': bucket_name,
                        'Key': object_key
                    },
                    ExpiresIn=3600  # URL expires in 1 hour (adjust as needed)
                )
                return {
                    'statusCode': 200,
                    'presigned_url': presigned_url
                }
            except NoCredentialsError:
                return {
                    'statusCode': 500,
                    'body': json.dumps({'error': 'Credentials not available'})
                }
            except Exception as e:
                return {
                    'statusCode': 500,
                    'body': json.dumps({'error': str(e)})
                }
          def _validate_bucket_key(full_path: str) -> bool:
            dirs = full_path.split("/")
            return len(dirs) == 2 and str(uuid.UUID(dirs[0])) == dirs[0] and dirs[1] in valid_file_names

      Environment:
        Variables:
          BUCKET_NAME: !Ref PatientBucket

  PresignedURLFunctionUrl:
    Type: AWS::Lambda::Url
    Properties:
      TargetFunctionArn: !GetAtt PresignedURLFunction.Arn
      AuthType: NONE
  DLQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub '${AWS::StackName}-DLQ'
      MessageRetentionPeriod: 1209600  # 14 days in seconds

  # Main SQS Queue
  ProcessingQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub '${AWS::StackName}-ProcessingQueue'
      VisibilityTimeout: 300  # 5 minutes (should match Lambda timeout)
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt DLQueue.Arn
        maxReceiveCount: 3
  
  # S3 Event Notification to Lambda
  S3EventNotification:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !GetAtt PatientIDMapperFunction.Arn
      Action: lambda:InvokeFunction
      Principal: s3.amazonaws.com
      SourceArn: !Sub 'arn:aws:s3:::${PatientBucket}'

  MappingLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: LambdaBasicExecutionPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'
        - PolicyName: AllowS3Get
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource: '*'
              - Effect: Allow
                Action:
                  - sqs:SendMessage
                Resource: !GetAtt ProcessingQueue.Arn

  PatientIDMapperFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: MapPatients
      Handler: index.handler
      Runtime: python3.12
      Role: !GetAtt MappingLambdaExecutionRole.Arn
      Timeout: 300  # 5 minutes
      Code:
        ZipFile: |
          import json
          import boto3
          import os

          def handler(event, context):
              s3 = boto3.client('s3')
              
              bucket = '991175998352-cumulus-gic-connector-dev'
              # bucket = event['Records'][0]['s3']['bucket']['name']
              key = '06b29e4c-6b9b-4220-bf1e-dc0a7ea6e919/patients.txt'
              # key = event['Records'][0]['s3']['object']['key']
              print(f"Processing file: {key}")
              
              try:
                  response = s3.get_object(Bucket=bucket, Key=key)
                  content = response['Body'].read().decode('utf-8')
                  
                  lines = content.splitlines()
                  lines = lines[1:] # del header
                  return_lines = ['GIC_ID,MRN']
                  for line in lines:
                      return_lines.append(line + ',' + 'mrn-' + line)
                  return lines
                  
              except Exception as e:
                  print(f"Error processing file: {str(e)}")
                  return {
                      'statusCode': 500,
                      'body': f"Error processing file: {str(e)}"
                  }

      Layers:
        - !Sub '${DependenciesLayer}'

  DependenciesLayer:
    Type: AWS::Lambda::LayerVersion
    Properties:
      LayerName: AllPipDependenciesMapPatients
      Content:
        S3Bucket: !Ref ExternalDepsBucket
        S3Key: !Ref DependenciesZipKey
      CompatibleRuntimes:
        - python3.12

Outputs:
  LambdaFunctionName:
    Description: Name of the Lambda function
    Value: !Ref PatientIDMapperFunction
  LambdaFunctionArn:
    Description: ARN of the Lambda function
    Value: !GetAtt PatientIDMapperFunction.Arn
  DependenciesLayerArn:
    Description: ARN of the Dependencies Layer
    Value: !Ref DependenciesLayer